{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from pylab import *\n",
    "# import cv2\n",
    "# import itertools\n",
    "# from scipy.ndimage.interpolation import rotate, shift, zoom\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotion_name = [\"anger\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\", \"unknown\"]\n",
    "anger = 0\n",
    "disgust = 1\n",
    "fear = 2\n",
    "happy = 3\n",
    "sad = 4\n",
    "surprise = 5\n",
    "neutral = 6\n",
    "colors = ['red', 'brown', 'black', 'orange', 'blue', 'yellow', 'grey']\n",
    "\n",
    "max_data_points_keep = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_examples = 4000#35887\n",
    "n_classes = 7\n",
    "\n",
    "capacity = 2000\n",
    "batch_size = 1000\n",
    "min_after_dequeue = 1000\n",
    "hm_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load], [train] from scratch, or [continue] training? train\n"
     ]
    }
   ],
   "source": [
    "###################TENSORFLOW\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', './checkpoint/', 'the checkpoint dir')\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "x = tf.placeholder('float', [None, 2304]) #48*48=2304\n",
    "y = tf.placeholder('float',[None, n_classes])\n",
    "\n",
    "keep_rate = 0.8\n",
    "\n",
    "weights = {'W_conv1': tf.Variable(tf.random_normal([5, 5, 1, 32])), \n",
    "            'W_conv2': tf.Variable(tf.random_normal([3, 3, 32, 64])),\n",
    "            'W_conv3': tf.Variable(tf.random_normal([2, 2, 64, 128])), ##64 and 128 are arbitrary, doesn't have to be power of 2\n",
    "            'W_fc1': tf.Variable(tf.random_normal([6*6*128, 1024])),\n",
    "            'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "biases = {'b_conv1': tf.Variable(tf.random_normal([32])),\n",
    "            'b_conv2': tf.Variable(tf.random_normal([64])),\n",
    "            'b_conv3': tf.Variable(tf.random_normal([128])),\n",
    "            'b_fc1': tf.Variable(tf.random_normal([1024])),\n",
    "            'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=1)  # defaults to saving all variables - in this case w and b\n",
    "choice = input(\"[load], [train] from scratch, or [continue] training? \")\n",
    "while (not (choice == \"train\")) and (not (choice == \"load\") and (not (choice == \"continue\"))):\n",
    "    choice = input(\"Invalid input. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def maxpool2d(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2,1], padding='SAME')\n",
    "\n",
    "def conv_neural_network_model(data):\n",
    "    x = tf.reshape(data, shape=[-1, 48, 48, 1])\n",
    "    conv1 = conv2d(x, weights['W_conv1']) + biases['b_conv1'] ##here, images are still 48*48\n",
    "    conv1 = maxpool2d(conv1) ##images now 24*24\n",
    "    conv2 = conv2d(conv1, weights['W_conv2']) + biases['b_conv2']\n",
    "    conv2 = maxpool2d(conv2) ##images now 12*12\n",
    "    conv3 = conv2d(conv2, weights['W_conv3']) + biases['b_conv3']\n",
    "    conv3 = maxpool2d(conv3) ##images now 6*6\n",
    "\n",
    "    fc1 = tf.reshape(conv3, [-1, 6*6*128])\n",
    "    fc1 = tf.nn.relu(tf.matmul(fc1, weights['W_fc1'])+biases['b_fc1'])\n",
    "    fc1 = tf.nn.dropout(fc1, keep_rate)\n",
    "    #fc2 = tf.nn.relu(tf.matmul(fc1, weights['W_fc2'])+biases['b_fc2'])\n",
    "    #fc2 = tf.nn.dropout(fc2, keep_rate)\t\n",
    "    output = tf.matmul(fc1, weights['out'])+biases['out']\n",
    "\n",
    "    return output\n",
    "\n",
    "def val_to_one_hot(x):\n",
    "    ans = np.array([0, 0, 0, 0, 0, 0, 0])\n",
    "    ans[x]=1\n",
    "    return ans\n",
    "\n",
    "def plot_image(images, emotion_num, prediction, prediction_best_guess):\n",
    "    images = np.reshape(images, [48, 48])\n",
    "    correct_emotion = emotion_name[emotion_num]\n",
    "    best_guess = emotion_name[prediction_best_guess]\n",
    "    txt = \"\"\n",
    "    for k in range(n_classes):\n",
    "        txt +=  str(emotion_name[k]) + \": \" + str(round(prediction[0][k], 3)) + \"\\n\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    left = fig.add_subplot(121)\n",
    "    title(\"Correct emotion: \" + correct_emotion+\"\\n\"+\"Predicted emotion: \" + best_guess, fontweight='bold')\n",
    "    imshow(images,cmap='gray')\n",
    "    \n",
    "    right = fig.add_subplot(122)\t\n",
    "    pos = arange(7)+.5    # the bar centers on the y axis\n",
    "    barh(pos, prediction.tolist()[0], align='center')\n",
    "    xlim([0, 1])\n",
    "    yticks(pos, emotion_name[0:7])\n",
    "    xlabel('Confidence')\n",
    "    grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def rand_jitter(temp):\n",
    "    temp = np.resize(temp, (48, 48))\n",
    "    if np.random.random() < 0.5:\n",
    "        temp = np.fliplr(temp)\n",
    "    #if np.random.random() < prob:\n",
    "    temp = shift(temp, shift=(np.random.randint(low=-4, high=4, size=2)))\n",
    "    #if np.random.random() < prob:\n",
    "    temp = rotate(temp, angle = np.random.randint(-20, 20, 1), reshape = False)\n",
    "    return np.resize(temp, (2304))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(['data/fer2013.csv'])\n",
    "reader = tf.TextLineReader(skip_header_lines=1) #skip_header_lines=1\n",
    "_, csv_row = reader.read(filename_queue)\n",
    "record_defaults = [[0], [\"\"]] #add extra [\"\"] if fer2013.csv\n",
    "emotion, pixel_array = tf.decode_csv(csv_row, record_defaults=record_defaults) #add extra ,__ if fer2013.csv\n",
    "\n",
    "emotion_batch, pixel_array_batch = tf.train.shuffle_batch(\n",
    "      [emotion, pixel_array], batch_size=batch_size, capacity=capacity,\n",
    "      min_after_dequeue=min_after_dequeue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = conv_neural_network_model(x)\n",
    "normalized_prediction = tf.nn.softmax(conv_neural_network_model(x))\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "train_step = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "confusion_matrix = [[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parent directory of ./checkpoint/model.ckpt doesn't exist, can't save.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fc79cb73b0ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                                 \u001b[0;31m#saver.save(sess, FLAGS.checkpoint_dir+\"model.ckpt\", global_step=epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                 \u001b[0;31m#print(\"Progress checkpoint saved\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"model.ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhm_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NN model has been saved.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vyom/anaconda3/envs/CERN/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsDirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m       raise ValueError(\n\u001b[0;32m-> 1354\u001b[0;31m           \"Parent directory of {} doesn't exist, can't save.\".format(save_path))\n\u001b[0m\u001b[1;32m   1355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parent directory of ./checkpoint/model.ckpt doesn't exist, can't save."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\ttf.global_variables_initializer().run()\n",
    "\tcoord = tf.train.Coordinator()\n",
    "\tthreads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "\t## DO A TRAIN\n",
    "\tif (choice == \"continue\"):\n",
    "\t\tckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
    "\t\tif ckpt and ckpt.model_checkpoint_path:\n",
    "\t\t\tsaver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\t\t\tprint(\"NN model has been restored for continued training!\")\n",
    "\tif (choice == \"train\" or choice == \"continue\"):\n",
    "\t\tfor epoch in range(hm_epochs):\n",
    "\t\t\tepoch_loss = 0\n",
    "\t\t\tfor batch in range(int(n_examples/batch_size)):\n",
    "\t\t\t\tcur_emotion_batch, cur_pixel_array_batch = sess.run([emotion_batch, pixel_array_batch])\t\t\n",
    "\t\t\t\tappend_matrix_emotion = list()\n",
    "\t\t\t\tappend_matrix_name = list()\n",
    "\t\t\t\tfor item in range(batch_size):\n",
    "\t\t\t\t\tcur_pixel_array_batch[item] = np.fromstring(cur_pixel_array_batch[item], dtype=int, sep=\" \")\n",
    "\t\t\t\t\tappend_matrix_emotion.append(cur_pixel_array_batch[item])\n",
    "\t\t\t\t\tone_hot_temp = val_to_one_hot(cur_emotion_batch[item])\n",
    "\t\t\t\t\tappend_matrix_name.append(one_hot_temp)\n",
    "\t\t\t\t\t##add 4 jitter versions\n",
    "\t\t\t\t\t'''\n",
    "\t\t\t\t\tfor _ in range(2):\n",
    "\t\t\t\t\t\tappend_matrix_emotion.append(rand_jitter(cur_pixel_array_batch[item]))\n",
    "\t\t\t\t\t\tappend_matrix_name.append(one_hot_temp)\n",
    "\t\t\t\t\t'''\n",
    "\t\t\t\t_, c = sess.run([train_step, cost], feed_dict = {x: np.array(append_matrix_emotion), y: np.array(append_matrix_name)}) #np.reshape(cur_pixel_array_batch[item], [1, 2304])\n",
    "\t\t\t\tepoch_loss += c\t\n",
    "\t\t\tprint('Epoch', epoch+1, 'completed out of', hm_epochs, 'loss:', epoch_loss)\n",
    "\t\t\t#if epoch % 5 == 0:\n",
    "\t\t\t\t#saver.save(sess, FLAGS.checkpoint_dir+\"model.ckpt\", global_step=epoch)\n",
    "\t\t\t\t#print(\"Progress checkpoint saved\")\n",
    "\t\tsaver.save(sess, FLAGS.checkpoint_dir+\"model.ckpt\", global_step=hm_epochs)\n",
    "\t\tprint(\"NN model has been saved.\")\n",
    "\telse:\n",
    "\t\tckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
    "\t\tif ckpt and ckpt.model_checkpoint_path:\n",
    "\t\t\tsaver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\t\t\t'''\n",
    "\t\t\tprint(\"NN model has been restored!\")\n",
    "\t\t\tprint(weights['W_conv1'].eval())\n",
    "\t\t\t\n",
    "\t\t\tprint(sess.run(weights['W_conv2']))\n",
    "\t\t\tprint(sess.run(weights['W_conv3']))\n",
    "\t\t\tprint(sess.run(weights['W_fc1']))\n",
    "\t\t\tprint(sess.run(weights['out']))\n",
    "\n",
    "\t\t\tprint(sess.run(biases['b_conv1']))\n",
    "\t\t\tprint(sess.run(biases['b_conv2']))\n",
    "\t\t\tprint(sess.run(biases['b_conv3']))\n",
    "\t\t\tprint(sess.run(biases['b_fc1']))\n",
    "\t\t\tprint(sess.run(biases['out']))\n",
    "\t\t\t'''\n",
    "\t\telse:\n",
    "\t\t\tprint(\"no checkpoint found???\")\n",
    "\t\t\texit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
